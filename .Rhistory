name="CSA",
type="did",
model_call="att_gt",
model_formula= ~ unemploymentrate,
model_args=list(yname="crude.rate", tname="year", idname="state",
gname="treatment_year", xformla = formula("~ unemploymentrate")),
se_adjust=c("none"))
five_percent_effect <- 0.05*mean(overdoses$crude.rate, na.rm = T)
ten_percent_effect <- 0.10*mean(overdoses$crude.rate, na.rm = T)
scenarios_no_confounding <- list(five_percent_effect, ten_percent_effect)
sim_config <- optic_simulation(
x = overdoses,
models = list(csa),
iters = 50,
method = "no_confounding",
unit_var = "state",
treat_var = "state",
time_var = "year",
effect_magnitude = scenarios_no_confounding,
n_units = c(5,30),
effect_direction = c("neg"),
policy_speed = c("instant", "slow"),
n_implementation_periods = c(6))
sim_results <- dispatch_simulations(
sim_config,
use_future = F,
seed = 978,
verbose = TRUE)
x
model_formula
model_call
te
effect_direction
concurrent
outcome
modifier
model_call
# Debug optic:
library(optic)
library(did)
library(augsynth)
library(fixest)
library(tidyr)
data(overdoses)
overdoses$crude.rate <- 1e5*(overdoses$deaths/overdoses$population)
ar <- optic_model(
name = "AR",
type = "autoreg",
call = "lm",
formula = crude.rate ~ unemploymentrate + as.factor(year) + treatment_change,
se_adjust = "none")
ascm <- list(
name="ASCM",
type="multisynth",
model_call="multisynth",
model_formula=crude.rate ~ treatment_level | unemploymentrate,
model_args=list(unit=as.name("state"), time=as.name("year"), fixedeff=TRUE,
form=crude.rate ~ treatment_level | unemploymentrate),
se_adjust="none")
csa <- list(
name="CSA",
type="did",
model_call="att_gt",
model_formula= ~ unemploymentrate,
model_args=list(yname="crude.rate", tname="year", idname="state",
gname="treatment_year", xformla = formula("~ unemploymentrate")),
se_adjust=c("none"))
five_percent_effect <- 0.05*mean(overdoses$crude.rate, na.rm = T)
ten_percent_effect <- 0.10*mean(overdoses$crude.rate, na.rm = T)
scenarios_no_confounding <- list(five_percent_effect, ten_percent_effect)
sim_config <- optic_simulation(
x = overdoses,
models = list(csa),
iters = 50,
method = "no_confounding",
unit_var = "state",
treat_var = "state",
time_var = "year",
effect_magnitude = scenarios_no_confounding,
n_units = c(5,30),
effect_direction = c("neg"),
policy_speed = c("instant", "slow"),
n_implementation_periods = c(6))
sim_results <- dispatch_simulations(
sim_config,
use_future = F,
seed = 978,
verbose = TRUE)
optic
help(optic)
library(optic)
help(optic)
.libpaths()
.libPaths()
remove.packages("optic")
2+2
library(Matrix)
help(Matrix)
rm(list = ls())
library(optic)
library(did)
library(augsynth)
library(did2s)
m_es <- optic_model(
name = "twfe",
type = "eventstudy",
call = "feols",
formula = crude.rate ~ unemploymentrate + i(time_to_treat, ref = c(-1, Inf)) | state + year,
model_args = list(cluster = "state"),
se_adjust = "none",
)
m_sa <- optic_model(
name = "sa",
type = "eventstudy",
call = "feols",
formula = crude.rate ~ unemploymentrate + sunab(treatment_date, time_to_treat, ref.p = c(-1, .F)) | state + year,
model_args = list(cluster = "state"),
se_adjust = "none"
)
m_csa <- optic_model(
name = "csa_did",
type = "did",
call = "att_gt",
#Formula below technically doesn't do anything but OPTIC requires it; we might want to fix this? Same for several other calls like multisynth
formula = crude.rate ~ unemploymentrate + treatment_level,
model_args = list(yname = "crude.rate", tname = 'year', idname = 'state',
gname = 'treatment_date', xformla = formula(~ unemploymentrate)),
se_adjust = "none"
)
library(rmarkdown)
compiler::setCompilerOptions(optimize = 2)
rm(list = ls())
library(ggplot2)
library(irr)
# Extensions to ggplot for various bespoke needs
library(ggridges)  # For geom_ridges
library(gridExtra) # For arrangeGrob, to pass ggplots from function
library(grid)      # For grid.draw, after collecting a list of grobs
library(cowplot)   # For plot_grid, arranging p lots in a specific orientation
library(ggforce)   # For facet_wrap_paginate
library(ggpubr)    # Easy arrange w/ separate legend
library(ggstance)  # For position_dodgev
library(extrafont)
font_import()
library(data.table)
library(plyr)
library(dplyr)
library(stringr)
library(readxl)
library(kableExtra)      # For generating Latex tables from dataframes
setwd("C:/users/griswold/Documents/GitHub/twitter-representative-pop/public_facing")
df     <- fread("./data/results/stance_results_12_11_24_v4.csv")
outcome <- c("cont", "bin", "cat")
data_names      <- c('pol', 'user', 'kawintiranon', 'li')
data_names_long <- c("116th U.S. Congress", "Twitter Users",
"Kawintiranon & Singh, 2021",  "P-Stance")
data_name_lookup <- data.table("data_name" = data_names, "data_name_long" = data_names_long)
# Rename variables in the plot; note, position order matters
model_name_full <- c("GPT-4 Omni", "GPT-4", "GPT-3.5 Turbo", "DeBERTa-NLI", "DistilBERT Uncased",
"SiEBERT", "RoBERTa-TweetEval", "VADER", "Hu & Liu", "NRC", "SenticNet 4",
"SO-CAL", "SentiWordNet")
model_name_short <- c("gpt4o", "gpt4", "gpt35", "deberta", "distilbert", "siebert",
"tweetnlp", "vader", "huliu", "nrc", "senticnet", "socal_google", "sentiword")
method_type <- c(rep("Large \nLanguage \nModel", 3), rep("Supervised \nLanguage \n Model", 4), rep("Lexical", 6))
method_lookup <- data.table("model_name" = model_name_short, "model_name_long" = model_name_full, "method_type" = method_type)
df <- join(df, method_lookup, type = 'left', by = 'model_name')
df <- join(df, data_name_lookup, type = 'left', by = 'data_name')
# Reorder methods for plotting purposes
df[, model_name := factor(model_name, levels = rev(model_name_short))]
df[, model_name_long := factor(model_name_long, levels = rev(model_name_full))]
# For reordering, I'm adding an additional omitted category group. This group will
# correspond to validation data added to the dataframe when plotting the empirical distributions.
df[, method_type := factor(method_type, levels = c("Large \nLanguage \nModel", "Supervised \nLanguage \n Model",
"Lexical", "Validation"))]
# Change prompt, tune, and subject names to make plots look a little nicer
df[, prompt_name_long := mapvalues(prompt_name, paste0("p", 1:6),
c("Sentiment", "Stance (Alt)", "Stance",
"Stance (Binary)",  "Few-Shot", "Chain-of-Thought"))]
df[, prompt_name_long := factor(prompt_name_long, levels = c("Sentiment", "Stance (Alt)", "Stance (Binary)",
"Stance", "Few-Shot", "Chain-of-Thought"))]
df[, subject := str_to_title(subject)]
df[, tune_name_long := mapvalues(tune_data, c("handcode", "party", "nominate"),
c("Tuned (Human-Coded)", "Tuned (Party Affiliation)", "Tuned (DW-Nominate)"))]
df[, tune_name_long := factor(tune_name_long, levels = c("Tuned (Human-Coded)", "Tuned (Party Affiliation)", "Tuned (DW-Nominate)"))]
pol_scored <- fread("./data/raw/pol_tweets_scored.csv")[, .(text, subject_name, scorer_1, scorer_2)]
setnames(pol_scored, "subject_name", "subject")
user_scored <- fread("./data/raw/user_handcode_train.csv")[, .(text, subject, scorer_1, scorer_2)]
df_combine <- rbind(pol_scored, user_scored)
df_combine[, subject := ifelse(subject == "biden", "Biden", "Trump")]
rater_scatter <- ggplot(df_combine, aes(x = scorer_1, y = scorer_2)) +
geom_abline(alpha = 1, linetype = 21, intercept = 0, slope = 1) +
geom_smooth(method = 'lm', alpha = 0.5) +
geom_point(alpha = 0.2) +
facet_wrap(~subject, nrow = 2) +
lims(x = c(-1, 1), y = c(-1, 1)) +
theme_bw() +
labs(x = "Annotator 1",
y = "Annotator 2") +
theme(strip.background = element_blank(),
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.9),
plot.title = element_text(hjust = 0),
strip.text = element_text(size = 12, family = 'sans'),
strip.placement = 'outside',
panel.spacing = unit(1, "lines"),
plot.subtitle = element_text(hjust = 0),
axis.title = element_text(size = 12, family = "sans"))
ggsave("./figs/Fig S. Handcode Compare.pdf", rater_scatter,
device = 'pdf', bg = "transparent",
height = 8.27, width = 8.27, unit = 'in')
# Calculate overall ICC
icc(as.matrix(df_combine[, .(scorer_1, scorer_2)]), model = "oneway", unit = "single", type = "consistency")
# Convert to binary scores and calculate Cohen's Kappa:
df_combine[, scorer_1 := ifelse(scorer_1 > 0, 1, 0)]
df_combine[, scorer_2 := ifelse(scorer_2 > 0, 1, 0)]
kappa2(as.matrix(df_combine[, .(scorer_1, scorer_2)]), weight = "equal")
# Produce contingency table:
table(df_combine[subject == "Biden"]$scorer_1, df_combine[subject == "Biden"]$scorer_2)
table(df_combine[subject == "Trump"]$scorer_1, df_combine[subject == "Trump"]$scorer_2)
df
users_scored
user_scored
View(user_scored)
names(user_scored)
user_scored[393]
df
df[data_name == "Twitter Users" & id == 357]
df[data_name == "Twitter Users" & id == 357 - 250]
df[data_name_long == "Twitter Users" & id == 357]
df[data_name_long == "Twitter Users" & id == 349]
df[data_name_long == "Twitter Users" & id == 303]
df[data_name_long == "Twitter Users" & id == 393]
# Calculate overall ICC
icc(as.matrix(df_combine[, .(scorer_1, scorer_2)]), model = "oneway", unit = "average", type = "consistency")
# Calculate overall ICC
icc(as.matrix(df_combine[, .(scorer_1, scorer_2)]), model = "oneway", unit = "single", type = "consistency")
# Convert to binary scores and calculate Cohen's Kappa:
df_combine[, scorer_1 := ifelse(scorer_1 > 0, 1, 0)]
df_combine[, scorer_2 := ifelse(scorer_2 > 0, 1, 0)]
kappa2(as.matrix(df_combine[, .(scorer_1, scorer_2)]), weight = "equal")
summary(kappa2(as.matrix(df_combine[, .(scorer_1, scorer_2)]), weight = "equal"))
test <- kappa2(as.matrix(df_combine[, .(scorer_1, scorer_2)]), weight = "equal"))
test
test <- kappa2(as.matrix(df_combine[, .(scorer_1, scorer_2)]), weight = "equal")
test
summary(test)
rm(list = ls())
library(data.table)
library(ggplot2)
library(ggstance)
library(ggpubr)
library(MASS)
library(stringr)
library(scales)
library(units)
sf::sf_use_s2(FALSE)
##########################################
# Reported Crime Trends by Policy Status #
##########################################
df <- fread("./data/processed/df_crime_analysis.csv")
setwd("C:/users/griswold/Documents/github/cfh_az/")
rm(list = ls())
library(data.table)
library(ggplot2)
library(ggstance)
library(ggpubr)
library(MASS)
library(stringr)
library(scales)
library(units)
sf::sf_use_s2(FALSE)
##########################################
# Reported Crime Trends by Policy Status #
##########################################
df <- fread("./data/processed/df_crime_analysis.csv")
# Plot average effects within non-treated sites
# and effects within treated sites.
df_avg <- df[total_population >= 10000 & !is.na(burglary_total) & burglary_total != 0 & outlier == F, ]
df_avg[is.na(post_treat), post_treat := 0]
df_avg[, post_treat := as.factor(post_treat)]
# Remove tucson from 2021 (which didn't appear to report
# data to ucr).
df_avg <- df_avg[!(year == 2021 & location == 'Tucson')]
df_avg[, burglary_count := (burglary_total*total_population)/1000]
df_avg[, burglary_count := sum(.SD$burglary_count), by = c("year", "post_treat")]
df_avg[, pop_group := sum(.SD$total_population), by = c("year", "post_treat")]
df_avg[, burglary_total := 10000*(burglary_count/pop_group)]
df_avg[, assault_count := (assault_total*total_population)/1000]
df_avg[, assault_count := sum(.SD$assault_count), by = c("year", "post_treat")]
df_avg[, pop_group := sum(.SD$total_population), by = c("year", "post_treat")]
df_avg[, assault_total := 10000*(assault_count/pop_group)]
df_avg <- unique(df_avg[, .(year, burglary_total, assault_total, post_treat)])
df_avg[, post_treat := ifelse(post_treat == 0, "Cities without a program", "Cities with Crime-Free Housing")]
df_avg <- melt(df_avg, id.vars = c("year", "post_treat"), value.name = "totals", variable.name= "crime_type")
df_avg[, crime_type := ifelse(crime_type == "burglary_total", "Burglaries", "Assaults")]
df_avg <- unique(df_avg)
df_avg
write.csv("crime_trends_per_1k_people.csv", row.names = F)
write.csv(df_avg, "crime_trends_per_1k_people.csv", row.names = F)
p2 <- df_avg[year == 2010 & year == 2023,]
p2
p2 <- df_avg[year == 2010 | year == 2023,]
p2
df_min <- df_avg[year == 2010 | year == 2023,]
dcast(df_min, year ~ post_treat + crime_type)
dcast(df_min, post_treat + crime_type ~ year)
df_min <- dcast(df_min, post_treat + crime_type ~ year)
df_min
setnames(df_min, c("2010", "2023"), c("rate_2010", "rate_2023"))
df_min <- df_avg[year == 2010 | year == 2023,]
df_min
ggplot(df_min, aes(x = year, y = totals)) +
geom_point() +
geom_line() +
facet_wrap(post_treat ~ crime_type)
ggplot(df_min, aes(x = year, y = totals)) +
geom_point() +
geom_line() +
facet_wrap(crime_type ~ post_treat)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
facet_wrap(crime_type)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
facet_wrap(~crime_type)
df_min <- df_avg[year == 2010 | year == 2020,]
df_min <- dcast(df_min, post_treat + crime_type ~ year)
setnames(df_min, c("2010", "2023"), c("rate_2010", "rate_2023"))
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
facet_wrap(~crime_type)
df_min <- df_avg[year == 2010 | year == 2020,]
setnames(df_min, c("2010", "2023"), c("rate_2010", "rate_2023"))
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
facet_wrap(~crime_type)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
facet_wrap(~crime_type, ncol = 1, strip.position = "left")
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
lims(y = c(0, 200)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left")
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
lims(y = c(0, 200)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic()
ggsave(filename = "./figs/crime_trend_proto.svg", height = 8.27, width = 8.27)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic()
df_min <- df_avg[year == 2010 | year == 2023,]
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2023)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic()
df_min <- df_avg[year == 2010 | year == 2020,]
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point() +
geom_line() +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = elemen_blank())
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 2) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 3) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggsave(filename = "./figs/crime_trend_proto.svg", height = 8.27, width = 4.27)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 3) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#a6cee3", "#b2df8a"))
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 3) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#a6cee3", "#b2df8a")) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 3) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#66c2a5", "#8da0cb")) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 3) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#8da0cb", "#66c2a5"")) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 4) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#8da0cb", "#66c2a5")) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggsave(filename = "./figs/crime_trend_proto.svg", height = 8.27, width = 4.27)
ggsave(filename = "./figs/crime_trend_proto.svg", height = 4.27, width = 4.27)
ggplot(df_min, aes(x = year, y = totals, color = post_treat)) +
geom_point(size = 4) +
geom_line(size = 1) +
labs(y = "") +
lims(y = c(0, 200)) +
scale_x_continuous(breaks = c(2010, 2020)) +
scale_color_manual(values = c("#8da0cb", "#66c2a5")) +
facet_wrap(~crime_type, ncol = 1, strip.position = "left") +
theme_classic() +
theme(strip.background = element_blank(),
strip.text = element_text(angle = 0),
axis.ticks = element_blank(),
legend.position = "none",
line = element_blank(),
axis.text.y = element_blank())
ggsave(filename = "./figs/crime_trend_proto.svg", height = 4.27, width = 4.27)
df_min
setorder(df_min, post_treat, year)
df_min
setorder(df_min, crime_type, year, post_treat)
df_min
p1 <- ggplot(df_avg, aes(x = year, y = totals, color = post_treat)) +
geom_line(linewidth = 1) +
facet_wrap(~crime_type, ncol = 2) +
scale_x_continuous(limits = c(2010, 2020), breaks = seq(2010, 2020, 5)) +
labs(title = "Assaults and burglaries do not decrease more in cities with crime-free housing \nthan cities without programs",
x = "Year",
y = "Reported crimes per\n 10,000 people",
color = "",
caption = "Source: FBI UCR, 2010 - 2020. \nNotes: Burglaries include forced entry, non-forced entry, and attempted. \nAssaults include those with a gun, with a knife, with a weapon, \nunarmed, and simple assaults. Data displayed for cities in AZ\n w/ populations greater than 10,000.") +
theme_bw() +
theme(strip.background = element_blank(),
legend.position = "bottom",
axis.text = element_text(family = 'sans', size = 10),
plot.title = element_text(family = 'sans', size = 14),
axis.title = element_text(family = 'sans', size = 12),
strip.text = element_text(size = 12, family = 'sans'))
p1
